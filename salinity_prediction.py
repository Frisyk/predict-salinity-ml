# -*- coding: utf-8 -*-
"""salinity prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/salinity-prediction-71a1fec2-1fa7-4207-9ce5-01450f44c68f.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250303/auto/storage/goog4_request%26X-Goog-Date%3D20250303T041031Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D392dbf4183dab65e05fd5c61b114c3e4bc5685e0c41431d40acd70a2912a71b177857bd60e7166df38d2d73b19590f2661fdfd36b0774d9f747528099fb924b4729db0641b97c410b8b4277615af84042f3e3575131e875d0d4e9d37d30a942f7db663116fedb3f2f2189a07c63aad510b770ad914373463351df228c917e9070f73b9b4b2fc6d0e6af508e588cbc31326d74ef15bee6df25e71f76ed4faed2afd4105656e107d42dbd31f2ce72205e8cd418ed4c8531c031751907a081595cfddb0f217da0c32b9416632b9ac1a7dcc853a56b4a57c96da3157c059510a67b457ff1bb51016f368a240f3ec0b1be80b92e9ade399fe34c71eca4cfe02e582fc
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
lainguyn123_student_performance_factors_path = kagglehub.dataset_download('lainguyn123/student-performance-factors')
patricklford_underway_pco_and_ocean_data_rv_j_clark_ross_path = kagglehub.dataset_download('patricklford/underway-pco-and-ocean-data-rv-j-clark-ross')
adilshamim8_education_and_career_success_path = kagglehub.dataset_download('adilshamim8/education-and-career-success')
zabihullah18_student_performance_path = kagglehub.notebook_output_download('zabihullah18/student-performance')

print('Data source import complete.')

"""# Data Loading"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
import os

folder_path = "/kaggle/input/underway-pco-and-ocean-data-rv-j-clark-ross"

csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]

df_list = [pd.read_csv(os.path.join(folder_path, file)) for file in csv_files]
df = pd.concat(df_list, ignore_index=True)

df.head()

"""# Exploratory Data Analysis (EDA)

## Variable Description
"""

df.info()

"""Di dapatkan 16 fitur dalam dataset yaitu:
1. **JD_GMT** *(Julian Date - Greenwich Mean Time)*  
   Format waktu dalam **Julian Date**, yang digunakan dalam astronomi dan ilmiah untuk menyatakan tanggal dalam satuan hari sejak 1 Januari 4713 SM.  
2. **DATE_UTC__ddmmyyyy** *(Tanggal UTC - Hari/Bulan/Tahun)*  
   Tanggal pencatatan data dalam format **ddmmyyyy** (misalnya, *01012022* berarti 1 Januari 2022).  
3. **TIME_UTC_hh:mm:ss** *(Waktu UTC - Jam:Menit:Detik)*  
   Waktu pencatatan dalam **Coordinated Universal Time (UTC)** dalam format jam:menit:detik.  
4. **LAT_dec_degree** *(Latitude dalam Derajat Desimal)*  
   Posisi lintang lokasi pengambilan data dalam **derajat desimal**.  
   **Nilai positif** → Belahan bumi **utara** (N).  
   **Nilai negatif** → Belahan bumi **selatan** (S).  
5. **LONG_dec_degree** *(Longitude dalam Derajat Desimal)*  
   Posisi bujur dalam **derajat desimal**.  
   **Nilai positif** → Bujur **timur** (E).  
   **Nilai negatif** → Bujur **barat** (W).  
6. **xCO2_equ[umol/mol]** *(Konsentrasi CO₂ pada Keseimbangan - Mikromol per Mol)*  
   Konsentrasi **karbon dioksida (CO₂)** dalam air yang telah mencapai **keseimbangan dengan atmosfer**.  
   Diukur dalam **mikromol per mol (μmol/mol)**.  
7. **Patm [hPa]** *(Tekanan Atmosfer dalam Hektopascal)*  
   Tekanan atmosfer di lokasi pengukuran dalam **hektopascal (hPa)**.  
   Tekanan standar di permukaan laut biasanya sekitar **1013 hPa**.  
8. **Tequ [deg.C]** *(Suhu Keseimbangan dalam Derajat Celcius)*  
   Suhu pada titik **keseimbangan gas-air** dalam **derajat Celsius**.  
9. **SST [deg.C]** *(Sea Surface Temperature - Suhu Permukaan Laut dalam Derajat Celsius)*  
   Suhu permukaan air laut dalam **derajat Celsius**.  
   Parameter penting untuk mempelajari **perubahan iklim dan sirkulasi laut**.  
10. **Sal** *(Salinitas atau Kadar Garam dalam PSU - Practical Salinity Unit)*  
   Mengukur **kadar garam dalam air laut**.  
   Satuan yang digunakan biasanya **PSU (Practical Salinity Unit)**, di mana air laut rata-rata memiliki salinitas **sekitar 35 PSU**.  
11. **pCO2_sw[uatm]** *(Tekanan Parsial CO₂ di Air Laut dalam Mikro Atmosfer)*  
   **Tekanan parsial karbon dioksida (CO₂) dalam air laut** dalam satuan **μatm (mikro atmosfer)**.  
   Semakin tinggi nilai ini, semakin banyak CO₂ yang terlarut dalam air laut.  
12. **pCO2_atm[uatm]** *(Tekanan Parsial CO₂ di Atmosfer dalam Mikro Atmosfer)*  
   **Tekanan parsial CO₂ di atmosfer** dalam satuan **μatm**.  
   Digunakan untuk membandingkan konsentrasi CO₂ antara laut dan atmosfer.  
13. **fCO2_sw[uatm]** *(Tekanan Parsial CO₂ yang Disesuaikan dengan Faktor Aktivitas di Laut)*  
   Sama seperti **pCO2_sw**, tetapi dikoreksi dengan faktor aktivitas untuk memperhitungkan kelarutan CO₂ di air laut.  
14. **fCO2_atm[uatm]** *(Tekanan Parsial CO₂ yang Disesuaikan dengan Faktor Aktivitas di Atmosfer)*  
   Sama seperti **pCO2_atm**, tetapi dikoreksi dengan faktor aktivitas untuk memperhitungkan pengaruh tekanan dan suhu udara.  
15. **xCO2atm_dry[umol/mol]** *(Konsentrasi CO₂ Kering di Atmosfer dalam Mikromol per Mol)*  
   **Konsentrasi karbon dioksida di udara kering** dalam **μmol/mol**.  
   Ini adalah nilai konsentrasi CO₂ setelah menghilangkan pengaruh kelembaban udara.  
16. **Pequ [hPa]** *(Tekanan di Kamar Keseimbangan dalam Hektopascal)*  
   Tekanan udara dalam **ruang keseimbangan** di mana pengukuran pCO₂ dilakukan.  
   Digunakan untuk memperbaiki dan menyesuaikan data pCO₂ agar lebih akurat.

**Nama fitur-fitur tersebut kemudian diubah kedalam bahasa indonesia agar memudahkan pemahaman data.**
"""

rename_columns = {
    "JD_GMT": "waktu_julian",
    "LAT_dec_degree": "latitude",
    "LONG_dec_degree": "longitude",
    "xCO2_equ[umol/mol]": "kadar_CO2_air",
    "Patm [hPa]": "tekanan_udara",
    "Tequ [deg.C]": "suhu_air_sensor",
    "SST [deg.C]": "suhu_permukaan_laut",
    "Sal": "salinitas",
    "pCO2_sw[uatm]": "tekanan_CO2_air",
    "pCO2_atm[uatm]": "tekanan_CO2_udara",
    "fCO2_sw[uatm]": "fraksi_CO2_air",
    "fCO2_atm[uatm]": "fraksi_CO2_udara",
    "xCO2atm_dry[umol/mol]": "kadar_CO2_kering",
    "Pequ [hPa]": "tekanan_air",
    "DATE_UTC__ddmmyyyy": "tanggal",
    "TIME_UTC_hh:mm:ss": "waktu"
}

df.rename(columns=rename_columns, inplace=True)

df.head()

df.describe()

"""## Univariate Analysis"""

numerical_features = [
    "waktu_julian", "latitude", "longitude", "kadar_CO2_air",
    "tekanan_udara", "suhu_air_sensor", "suhu_permukaan_laut", "salinitas",
    "tekanan_CO2_air", "tekanan_CO2_udara", "fraksi_CO2_air", "fraksi_CO2_udara",
    "kadar_CO2_kering", "tekanan_air"
]

df.hist(bins=50, figsize=(20,15))
plt.show()

"""### **Dari grafik di atas dapat diketahui:**  

1. **Waktu Julian** (Range: 0 hingga sekitar 365)
   - Distribusi menunjukkan beberapa puncak, kemungkinan terkait dengan musim atau periode pengambilan data.

2. **Latitude** (Range: Sekitar -75 hingga 75)  
   - Distribusi menunjukkan beberapa kluster, menandakan data diambil dari berbagai lokasi.

3. **Longitude** (Range: Sekitar -75 hingga 25)
   - Distribusi bervariasi dengan beberapa puncak, menunjukkan wilayah dengan banyak pengambilan sampel.

4. **Kadar CO₂ air** (Range: Sekitar 200 hingga 500)
   - Distribusi miring ke kanan dengan kepadatan tinggi antara 300–400.

5. **Tekanan Udara** (Range: Sekitar 960 hingga 1020)
   - Distribusi menyerupai distribusi normal dengan puncak sekitar 1000.

6. **Suhu Air Sensor** (Range: 0 hingga 15)
   - Terdapat beberapa kluster data yang bisa menunjukkan kondisi lingkungan berbeda.

7. **Suhu Permukaan Laut** (Range: 0 hingga 15)
   - Pola distribusi mirip dengan suhu air sensor.

8. **Salinitas** (Range: 28 hingga 34)
   - Sebagian besar data berada di kisaran 32–34, menunjukkan karakteristik perairan tertentu.

9. **Tekanan CO₂ Air** (Range: 150 hingga 450)
   - Distribusi cenderung normal dengan puncak sekitar 300–400.

10. **Tekanan CO₂ Udara** (Range: 360 hingga 480)
    - Memiliki distribusi yang sangat terpusat dengan puncak sekitar 400.

11. **Fraksi CO₂ Air**  (Range: 150 hingga 450)
    - Pola distribusi mirip dengan tekanan CO₂ air.

12. **Fraksi CO₂ Udara** (Range: 360 hingga 480)
    - Memiliki distribusi sangat terpusat di sekitar 400.

13. **Kadar CO₂ Kering** (Range: 400 hingga 480)
    - Distribusi mirip dengan tekanan CO₂ udara dan fraksi CO₂ udara.

14. **Tekanan Air** (Range: 960 hingga 1020)
    - Pola distribusi mirip dengan tekanan udara.

Dari analisis ini, terlihat beberapa variabel memiliki distribusi normal, sementara yang lain menunjukkan kluster atau distribusi miring. Ini bisa menjadi indikasi bahwa beberapa faktor memiliki korelasi dengan lokasi atau musim.

## Multivariate Analysis: Correlation Matrix

#### untuk mengukur besar korelasi antarfitur
"""

plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Grafik diatas menunjukkan keragaman korelasi antarfitur. Dengan nilai 1 yang menunjukkan korelasi tertinggi (sangat berkorelasi). Dapat disimpulkan fitur yang paling berkorelasi dengan salinitas adalah tekanan udara, suhu air sensor, suhu permukaan laut, tekanan air, dan kadar CO2 air.

### Kemudian dibuat grafik untuk menunjukan korelasi salinitas terhadap fitur - fitur diatas
"""

features = ["tekanan_CO2_air", "suhu_air_sensor", "suhu_permukaan_laut", "fraksi_CO2_air", "kadar_CO2_air"]

# Set ukuran figure
plt.figure(figsize=(12, 8))

for i, feature in enumerate(features, 1):
    plt.subplot(2, 3, i)
    sns.scatterplot(x=df[feature], y=df["salinitas"], alpha=0.7)
    sns.regplot(x=df[feature], y=df["salinitas"], scatter=False, color='red')
    plt.xlabel(feature)
    plt.ylabel("Salinitas")
    plt.title(f"Salinitas vs {feature}")

plt.tight_layout()
plt.show()

"""### fitur tekanan CO2 air, suhu air sensor, suhu permukaan laut, fraksi CO2 air dan kadar CO2 air memiliki korelasi yang positif terhadap salinitas.

# Data Preparation

## Drop unused Features
"""

df.drop(columns=["tanggal", "waktu", "waktu_julian", "latitude", "longitude", "tekanan_CO2_udara", "tekanan_air", "tekanan_udara", "fraksi_CO2_udara", "kadar_CO2_kering" ], inplace=True)
df.head()

"""## Check missing value"""

df.isnull().sum()

df.shape

"""## Check Outliers"""

num_features = df.select_dtypes(include=['number']).columns

num_plots = len(num_features)
rows = (num_plots // 6) + (num_plots % 6 > 0)  # Atur jumlah baris secara otomatis
fig, axes = plt.subplots(nrows=rows, ncols=6, figsize=(15, 6 * rows))

# Flatten axes untuk iterasi yang lebih mudah
axes = axes.flatten()

# Plot masing-masing boxplot di subplot
for i, feature in enumerate(num_features):
    sns.boxplot(x=df[feature], ax=axes[i])
    axes[i].set_title(feature)

# Hapus subplot kosong jika ada
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""Dari grafik diketahui terdapat outliers pada fitur "fraksi_CO2_air", "suhu_air_sensor", "suhu_permukaan_laut", "salinitas", dan "tekanan_CO2_air"

## Handling Outliers using IQR Method
"""

numerical_outlier = [
    "fraksi_CO2_air", "suhu_air_sensor", "suhu_permukaan_laut", "salinitas", "tekanan_CO2_air"
]

Q1 = df[numerical_outlier].quantile(0.25)
Q3 = df[numerical_outlier].quantile(0.75)
IQR = Q3 - Q1

# Menentukan batas bawah dan atas
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Menghapus outlier
df = df[~((df[numerical_outlier] < lower_bound) | (df[numerical_outlier] > upper_bound)).any(axis=1)]
df.shape

"""### Dataset berkurang menjadi 19879 sampel"""

num_features = df.select_dtypes(include=['number']).columns

# Tentukan jumlah subplot
num_plots = len(num_features)
rows = (num_plots // 6) + (num_plots % 6 > 0)  # Atur jumlah baris secara otomatis
fig, axes = plt.subplots(nrows=rows, ncols=6, figsize=(15, 6 * rows))

# Flatten axes untuk iterasi yang lebih mudah
axes = axes.flatten()

# Plot masing-masing boxplot di subplot
for i, feature in enumerate(num_features):
    sns.boxplot(x=df[feature], ax=axes[i])
    axes[i].set_title(feature)

# Hapus subplot kosong jika ada
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""#### Terlihat perbedaan sebelum dan sesudah dilakukannya IQR, data menjadi lebih bersih dari outliers

## Dimensionality Reduction with PCA
"""

from sklearn.decomposition import PCA

features_suhu = ["suhu_air_sensor", "suhu_permukaan_laut"]
features_CO2 = ["fraksi_CO2_air", "tekanan_CO2_air"]

pca_suhu = PCA(n_components=1, random_state=42)
df["komponen_suhu"] = pca_suhu.fit_transform(df[features_suhu]).flatten()

pca_CO2 = PCA(n_components=1, random_state=42)
df["komponen_CO2"] = pca_CO2.fit_transform(df[features_CO2]).flatten()


df.drop(features_suhu + features_CO2, axis=1, inplace=True)

print(f"Variansi yang dijelaskan oleh komponen suhu: {pca_suhu.explained_variance_ratio_[0]:.2f}")
print(f"Variansi yang dijelaskan oleh komponen CO2: {pca_CO2.explained_variance_ratio_[0]:.2f}")

"""## Train-Test-Split"""

from sklearn.model_selection import train_test_split

X = df.drop(columns=["salinitas"])
y = df["salinitas"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

print(f"Jumlah data latih: {X_train.shape[0]}")
print(f"Jumlah data uji: {X_test.shape[0]}")

"""## Standardization"""

from sklearn.preprocessing import StandardScaler

numerical_features = ["komponen_suhu","komponen_CO2", "kadar_CO2_air"]

scaler = StandardScaler()

scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])

X_test[numerical_features] = scaler.transform(X_test.loc[:, numerical_features])

X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

df.head()

"""# Modeling"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import ShuffleSplit

"""## Grid Search"""

from tabulate import tabulate

def grid_search_model(X, y):
    algos = {
        'KNN': {
            'model': KNeighborsRegressor(),
            'params': {
                'n_neighbors': [5, 7, 9, 11, 13, 15],
                'weights': ['uniform', 'distance']
            }
        },
        'Random Forest': {
            'model': RandomForestRegressor(),
            'params': {
                'n_estimators': [50, 100, 150],
                'max_depth': [8, 16, 32],
                'random_state': [42]
            }
        },
        'Gradient Boosting': {
            'model': GradientBoostingRegressor(),
            'params': {
                'n_estimators': [50, 100, 150],
                'learning_rate': [0.01, 0.05, 0.1],
                'max_depth': [3, 5, 7]
            }
        },
        'XGBoost': {
            'model': XGBRegressor(),
            'params': {
                'n_estimators': [50, 100, 150],
                'learning_rate': [0.01, 0.05, 0.1],
                'max_depth': [3, 5, 7]
            }
        }
    }

    scores = []
    best_models = {}
    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=123)

    for algo_name, config in algos.items():
        print(f"Training {algo_name}...")
        gs = GridSearchCV(config['model'], config['params'], cv=cv, scoring='r2', n_jobs=-1)
        gs.fit(X, y)
        best_models[algo_name] = gs.best_estimator_
        scores.append({
            'Model': algo_name,
            'Best Score': round(gs.best_score_, 4),
            'Best Params': gs.best_params_
        })

    df_results = pd.DataFrame(scores)

    print(tabulate(df_results, headers="keys", tablefmt="grid"))

    return df_results, best_models

results, best_models = grid_search_model(X_train, y_train)

"""- KNN memiliki skor tertinggi (0.8811) dengan **n_neighbors = 5** dan **weights = 'distance'**, menunjukkan bahwa model KNN dengan bobot berbasis jarak bekerja paling optimal dalam skenario ini.  
- Random Forest memiliki skor **0.871**, dengan **max_depth = 32**, **n_estimators = 100**, dan **random_state = 42**, yang menunjukkan bahwa model ini tetap kuat dengan kedalaman pohon yang cukup besar dan jumlah estimator yang optimal.  
- Gradient Boosting memiliki skor **0.8455**, dengan **learning_rate = 0.1**, **max_depth = 7**, dan **n_estimators = 150**, menunjukkan bahwa model ini bekerja cukup baik tetapi masih berada di bawah performa KNN dan Random Forest.  
- XGBoost memiliki skor **0.8568**, dengan **learning_rate = 0.1**, **max_depth = 7**, dan **n_estimators = 150**, yang mirip dengan Gradient Boosting tetapi menunjukkan sedikit peningkatan dalam performa.

## Best Algorithm
"""

# KNN
best_knn = best_models['KNN']

# Random Forest
best_rf = best_models['Random Forest']

# Gradient Boosting
best_gb = best_models['Gradient Boosting']

# XGBoost
best_xgb = best_models['XGBoost']

"""# Evaluation"""

from sklearn.metrics import mean_squared_error, r2_score
from tabulate import tabulate

model_dict = {
    'KNN': best_knn,
    'Random Forest': best_rf,
    'Gradient Boosting': best_gb,
    'XGBoost': best_xgb
}

results = []
mse = pd.DataFrame(columns=['Train MSE', 'Test MSE'], index=model_dict.keys())


for name, model in model_dict.items():
    y_pred = model.predict(X_test)

    results.append([name, mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred)])

    # Hitung MSE untuk train & test
    mse.loc[name] = [mean_squared_error(y_train, model.predict(X_train)),
                     mean_squared_error(y_test, y_pred)]

df_results = pd.DataFrame(results, columns=['Model', 'MSE', 'R²'])


df_results

mse

fig, ax = plt.subplots()
mse.sort_values(by='Test MSE', ascending=False).plot(kind='barh', ax=ax, zorder=3, color=['blue', 'orange', 'green', 'red'])
ax.set_title("Perbandingan MSE Model pada Data Test")
ax.set_xlabel("MSE")
ax.set_ylabel("Model")
ax.grid(zorder=0)
plt.show()

"""Berdasarkan evaluasi performa model menggunakan **Mean Squared Error (MSE)** dan **R²**, berikut adalah temuan utama:

- **KNN** menunjukkan performa terbaik dengan **MSE sebesar 0.0188** dan **R² sebesar 0.8836**, menandakan bahwa model ini memiliki kesalahan prediksi paling kecil serta kemampuan prediksi yang baik.
- **Random Forest** memiliki **MSE sebesar 0.0198** dan **R² sebesar 0.8773**, yang sedikit lebih rendah dibandingkan KNN tetapi tetap menunjukkan performa yang solid.
- **XGBoost** mencatat **MSE sebesar 0.0212** dan **R² sebesar 0.8692**, yang lebih baik dibandingkan Gradient Boosting tetapi masih di bawah KNN dan Random Forest.
- **Gradient Boosting** memiliki **MSE sebesar 0.0237** dan **R² sebesar 0.8534**, menunjukkan kesalahan prediksi yang lebih tinggi dibandingkan model lainnya.


- **KNN memiliki MSE sebesar 0.0 pada data latih**, yang menunjukkan bahwa model ini sepenuhnya menghafal data latih. Namun, model ini tetap mampu melakukan generalisasi yang baik pada data uji dengan MSE sebesar 0.0188.
- **Random Forest memiliki perbedaan kecil antara MSE latih (0.0026) dan MSE uji (0.0198)**, menunjukkan bahwa model ini mampu belajar dari pola data dengan baik tanpa mengalami overfitting.
- **Gradient Boosting dan XGBoost memiliki perbedaan kecil antara MSE latih dan uji**, tetapi MSE uji mereka tetap lebih tinggi dibandingkan KNN dan Random Forest. Ini menunjukkan bahwa meskipun model ini cukup baik dalam menangkap pola data, mereka tidak seoptimal KNN dan Random Forest dalam melakukan generalisasi.

"""

prediksi = X_test.iloc[5:10].copy()
pred_dict = {'y_true':y_test[5:10]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""- **Untuk data pertama (y_true = 33.46)**, semua model memberikan prediksi yang sangat dekat dengan nilai aktual, dengan KNN memprediksi 33.5 dan model lainnya memberikan nilai yang sama, yaitu 33.5.  
- **Pada data kedua (y_true = 34.15)**, semua model memberikan hasil yang hampir identik, dengan prediksi sebesar 34.1 untuk semua model.  
- **Pada data ketiga (y_true = 33.94)**, KNN memberikan prediksi sedikit lebih rendah (33.8), sementara Random Forest menghasilkan 33.9, sedangkan Gradient Boosting dan XGBoost memberikan prediksi tertinggi, yaitu 34.1.  
- **Pada data keempat (y_true = 33.60)**, KNN dan Random Forest memprediksi 33.5, sedangkan Gradient Boosting memberikan nilai sedikit lebih tinggi (33.7), dan XGBoost hampir sama dengan nilai aktual (33.6).  
- **Pada data kelima (y_true = 33.59)**, semua model memberikan prediksi yang sangat akurat, dengan nilai yang hampir identik dengan y_true, yaitu 33.6.  

Secara keseluruhan, semua model menunjukkan performa yang baik dengan prediksi yang sangat dekat dengan nilai aktual, terutama pada kasus-kasus di mana selisih antara y_true dan prediksi sangat kecil.
"""